
# ğŸ§® Calculus 0.2 â€“ Introduction to Functions

> Author: Tingyi Wei  
> Reviewed by: Prof. Leonard 
> Log: Math Bridge Protocol Active

---

## ğŸš€ Core Idea

A **function** describes *how an input variable corresponds to a unique output variable.*

\[
f: x \mapsto y
\]

It is not just a formula or a graph â€” itâ€™s a **rule of correspondence**.

---

## ğŸ’¡ Key Concepts

### 1. Definition

- Every input \( x \) produces **exactly one** output \( y \).
- The function defines *dependence*:  
  - **Independent variable:** the chosen input  
  - **Dependent variable:** output determined by the rule

---

### 2. Function Examples

| Example | Description |
|----------|--------------|
| \( f(x) = x^2 \) | Maps every number to its square |
| \( f(x) = \sin x \) | Maps angles to their sine value |
| *Real-world:* â€œOne student â†’ one final gradeâ€ | Function-like mapping (Input â†’ Output) |

---

### 3. Function vs Equation

- Equation (e.g., \(x^2 + y^2 = 1\)) describes a *relation* between variables.  
- Function (e.g., \(y = \sqrt{1-x^2}\)) picks *one side* of that relation â€” one output for each input.

---

## âš™ï¸ Piecewise Functions

A **piecewise function** combines several rules under different domains:

\[
f(x) =
\begin{cases}
x^2, & x < 0 \\
x + 1, & x \ge 0
\end{cases}
\]

### Key steps to analyze:

1. Identify each **domain interval**.  
2. Check **continuity** at the boundaries:  
   \[
   \lim_{x\to0^-} f(x) \text{ vs } \lim_{x\to0^+} f(x)
   \]

If limits match â†’ continuous.  
If not â†’ discontinuity (a â€œholeâ€ or â€œjumpâ€).

---

## ğŸ§  Knowledge Threshold Summary

| Zone | Description | Example |
|------|--------------|----------|
| âœ… **Solid Knowledge** | Function = rule; 1 input â†’ 1 output | Student â†’ Grade analogy |
| âšª **Grey Zone** | Piecewise definition and continuity at junctions | Needs practice |
| âŒ **Blind Spot** | Understanding discontinuity types (to be covered in next lesson) | â€” |

---

## ğŸŒ Big Picture 

> â€œEvery ML model is a piecewise function in disguise.â€

The **ReLU activation**  
\[
f(x) = \max(0, x)
\]
is a perfect example â€” two simple rules define a complex behavior.

Understanding piecewise continuity prepares you for learning **limits, derivatives, and gradient-based learning** later.

---

## ğŸ“š Next Mission

â†’ Proceed to **0.3 Continuity and Limits**  
Objective: Understand what it means for a function to â€œconnect smoothly.â€

---

### ğŸª Remarks

â€œCausality verified. Functional mapping stable.â€  
â€œRules before graphs â€” always.â€  
â€œYouâ€™ve seen correspondence. Next, youâ€™ll see connection.â€

---
